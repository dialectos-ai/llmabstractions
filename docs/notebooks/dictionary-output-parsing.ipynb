{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f186f21f5de96a",
   "metadata": {},
   "source": [
    "# Parse output as a dictionary object\n",
    "When prompting an LLM for structured (e.g. return JSON), you might get free text in addition to the requested content, or partially structured content. To convert the LLM output to a structured format, you can either relay on the LLM provider to do the parsing for you, or parse it inside your codebase. \n",
    "\n",
    "The `json_data_parser` function, will try to extract dictitonary or array content from an LLM response and raise an exception when it fails."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T16:06:02.989371Z",
     "start_time": "2024-12-28T16:06:02.980584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llmabstractions import json_data_parser\n",
    "\n",
    "llm_response = '''\n",
    "Here is the response\n",
    "```json\n",
    "{\n",
    "     \"key1\": \"value1\",\n",
    "     \"key2\": \"value2\"\n",
    " }\n",
    "```\n",
    "\n",
    "Is there something else?\n",
    "'''\n",
    "parsed_response = json_data_parser(llm_response)\n",
    "parsed_response"
   ],
   "id": "ee6a0b54261f212f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': 'value1', 'key2': 'value2'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In other cases, the content might be embeded in the text response. E.g. ",
   "id": "e724fc7900682c9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T16:07:07.976589Z",
     "start_time": "2024-12-28T16:07:07.971344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_response = '''\n",
    "Here is your array\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"key1\": \"value1\"\n",
    "    }, \n",
    "    {\n",
    "        \"key2\": \"value2\"\n",
    "    }\n",
    "]\n",
    "\n",
    "Is there something else?\n",
    "'''\n",
    "parsed_response = json_data_parser(llm_response)\n",
    "parsed_response"
   ],
   "id": "e68885e2c3bebdea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key1': 'value1'}, {'key2': 'value2'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `json_data_parser` function, will raise a `ParsingError` when it fails to extract JSON content from the text.",
   "id": "90691d27b0719512"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T16:09:02.111529Z",
     "start_time": "2024-12-28T16:09:01.858722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_response = '''\n",
    "Here is your array\n",
    "\n",
    "There is nothing to extract here\n",
    "'''\n",
    "parsed_response = json_data_parser(llm_response)\n",
    "parsed_response"
   ],
   "id": "6140d414c5f9c0bb",
   "outputs": [
    {
     "ename": "ParsingError",
     "evalue": "Unable to parse LLM output.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mParsingError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m llm_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'''\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124mHere is your array\u001B[39m\n\u001B[0;32m      3\u001B[0m \n\u001B[0;32m      4\u001B[0m \u001B[38;5;124mThere is nothing to extract here\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m----> 6\u001B[0m parsed_response \u001B[38;5;241m=\u001B[39m \u001B[43mjson_data_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mllm_response\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m parsed_response\n",
      "File \u001B[1;32m~\\dialectos-ai\\repos\\llmabstractions\\llmabstractions\\parsers\\json_response.py:71\u001B[0m, in \u001B[0;36mjson_data_parser\u001B[1;34m(llm_output)\u001B[0m\n\u001B[0;32m     68\u001B[0m             parsed_response \u001B[38;5;241m=\u001B[39m _extract_dict_or_array_from_text(llm_output)\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsed_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 71\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ParsingError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnable to parse LLM output.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m parsed_response\n",
      "\u001B[1;31mParsingError\u001B[0m: Unable to parse LLM output."
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
